{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sphere function, vectorized\n",
    "\n",
    "In the previous example, we solved the constrained Rosenbrock problem. This was a 2-dimensional problem, so we created two variables: $x$ and $y$.\n",
    "\n",
    "However, imagine we had a problem with 100 variables. It'd be pretty tedious to create these variables individually and do the math on each variable one-by-one. (Not to mention the fact that it'd be slow - rule #1 of scientific Python is to vectorize everything!)\n",
    "\n",
    "So, what we can do instead is (you guessed it) create variables that are vectors. Think of a vectorized variable as a box that contains $n$ entries, each of which is a scalar variable.\n",
    "\n",
    "Let's demonstrate this by finding the minimum of the n-dimensional sphere problem. The sphere problem, mathematically, is a simple quadratic program:\n",
    "\n",
    "$$ \\underset{x}{\\text{minimize }} \\sum x_i^2 $$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.3, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:      100\n",
      "\n",
      "Total number of variables............................:      100\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 1.0000000e+002 0.00e+000 2.00e+000   0.0 0.00e+000    -  0.00e+000 0.00e+000   0\n",
      "   1 0.0000000e+000 0.00e+000 0.00e+000 -11.0 1.00e+000    -  1.00e+000 1.00e+000f  1\n",
      "\n",
      "Number of Iterations....: 1\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Dual infeasibility......:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Constraint violation....:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Complementarity.........:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Overall NLP error.......:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 2\n",
      "Number of objective gradient evaluations             = 2\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 1\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.001\n",
      "Total CPU secs in NLP function evaluations           =      0.000\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |        0 (       0)        0 (       0)         2\n",
      "  nlp_grad_f  |        0 (       0)        0 (       0)         3\n",
      "  nlp_hess_l  |        0 (       0)        0 (       0)         1\n",
      "       total  |   2.00ms (  2.00ms)   1.99ms (  1.99ms)         1\n",
      "x = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import aerosandbox as asb\n",
    "import aerosandbox.numpy as np # Whoa! What is this? Why are we writing this instead of `import numpy as np`? Don't worry, we'll talk about this in the next tutorial :)\n",
    "\n",
    "N = 100 # Let's optimize in 100-dimensional space.\n",
    "\n",
    "opti = asb.Opti()\n",
    "\n",
    "# Define optimization variables\n",
    "x = opti.variable(\n",
    "    init_guess=np.ones(shape=N) # Creates a variable with an initial guess that is [1, 1, 1, 1,...] with N entries.\n",
    ") # Note that the fact that we're declaring a vectorized variable was *inferred* automatically the shape of our initial guess.\n",
    "\n",
    "# Define objective\n",
    "f = np.sum(x ** 2)\n",
    "opti.minimize(f)\n",
    "\n",
    "# Optimize\n",
    "sol = opti.solve()\n",
    "\n",
    "# Extract values at the optimum\n",
    "x_opt = sol.value(x)\n",
    "\n",
    "# Print values\n",
    "print(f\"x = {x_opt}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We find the solution of this optimization problem to be a vector of 100 zeroes - makes sense.\n",
    "\n",
    "Note that because this is an unconstrained quadratic program and we're using a modern second-order optimizer (IPOPT) as the backend, this solves in just one iteration (Newton step with $\\alpha=1$).\n",
    "\n",
    "Let's talk a bit more about vectorized variables. We demonstrated that one can create a vectorized variable with the syntax:\n",
    "\n",
    "```python\n",
    "x = opti.variable(\n",
    "    init_guess=np.ones(shape=N)\n",
    ")\n",
    "```\n",
    "\n",
    "One can also use the syntax:\n",
    "\n",
    "```python\n",
    "x = opti.variable(\n",
    "    init_guess=1,\n",
    "    n_vars=N,\n",
    ")\n",
    "```\n",
    "\n",
    "Which will also initialize a vector variable of length $N$ with initial guess of 1. Of course, let's say that you wanted to initialize each element of the vector $x$ to a different value; say, something like `np.linspace(0, 1, N)`. Then, you would have to use the syntax from the first example rather than that from the second.\n",
    "\n",
    "## A Note on Initial Guesses\n",
    "\n",
    "Note that when solving high-dimensional, nonlinear, nonconvex systems, it is very, very important to provide an initial guess that is as close to accurate as possible! This is true for both scalar and vector variables.\n",
    "\n",
    "## A Note on N-Dimensional Arrays of Optimization Variables\n",
    "\n",
    "Here, we demonstrated how 1-dimensional arrays of variables can be used in optimization with AeroSandbox.\n",
    "\n",
    "For simple analysis (without tracing derivatives), `aerosandbox.numpy` has all of the n-dimensional array capabilities of NumPy. However, in optimization (where we are tracing derivatives), only scalars, 1D, and 2D arrays are supported for now - but really, scalars and 1D arrays are usually the only things you ever need to use as optimization variables for engineering design optimization. (2D arrays of decision variables can occasionally appear in operations research problems such as the [transportation problem](https://personal.utdallas.edu/~scniu/OPRE-6201/documents/TP1-Formulation.pdf), but this usually doesn't occur in engineering design problems.)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}