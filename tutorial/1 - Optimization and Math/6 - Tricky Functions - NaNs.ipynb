{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tricky Functions and Cautionary Tales, Continued\n",
    "\n",
    "In the previous tutorial, we talked about discontinuities (functions that aren't $C_1$-continuous) as a common source of optimization problems.\n",
    "\n",
    "Let's talk about another: NaNs.\n",
    "\n",
    "NaNs are a familiar and terrifying sight to any battle-hardened computationalist.\n",
    "\n",
    "What's a NaN? It's the value that gets returned whenever a function gets evaluated anywhere outside of its domain. When do NaNs tend to appear? Several functions are common culprits:\n",
    "\n",
    "1. $\\sqrt x$ if $x < 0$. (Note: `aerosandbox.numpy` will evaluate this fine, but it can't trace automatic derivatives through complex math, so don't use this in optimization and try to avoid it in general.)\n",
    "\n",
    "2. More generally, any $x^y$ where $y$ is non-integer and $x < 0$.\n",
    "\n",
    "3. $\\ln x$ or $\\log x$ evaluated at $x < 0$.\n",
    "\n",
    "4. Infinities in either a function's value or its derivative.\n",
    "\n",
    "The problem with NaNs in optimization is twofold:\n",
    "\n",
    "1. We can't get a value for the objective function or constraint that is returning the NaN, so we don't know \"how good we're doing\".\n",
    "\n",
    "2. We can't get a gradient of the NaN-returning function, so we don't know which direction to look in order to return to the well-posed space.\n",
    "\n",
    "So, stay away from NaNs! This may seem easy, but it's much easier to introduce NaNs than one might imagine. Let's look at some examples:\n",
    "\n",
    "## Example 1: Unconstrained $\\sqrt x$ Minimization\n",
    "\n",
    "Let's start with an example that should obviously fail. We're going to try minimizing $\\sqrt x$, starting with an initial guess of $x = -1$. Because our initial point will return a NaN, this will obviously fail to solve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.3, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        1\n",
      "\n",
      "Error evaluating objective gradient at user provided starting point.\n",
      "  No scaling factor for objective function computed!\n",
      "Total number of variables............................:        1\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "\n",
      "Number of Iterations....: 0\n",
      "\n",
      "Number of objective function evaluations             = 0\n",
      "Number of objective gradient evaluations             = 1\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 0\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.001\n",
      "Total CPU secs in NLP function evaluations           =      0.000\n",
      "\n",
      "EXIT: Invalid number in NLP function or derivative detected.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "  nlp_grad_f  |        0 (       0)        0 (       0)         2\n",
      "       total  |   1.00ms (  1.00ms) 998.00us (998.00us)         1\n",
      "Error in Opti::solve [OptiNode] at .../casadi/core/optistack.cpp:159:\n",
      ".../casadi/core/optistack_internal.cpp:999: Assertion \"return_success(accept_limit)\" failed:\n",
      "Solver failed. You may use opti.debug.value to investigate the latest values of variables. return_status is 'Invalid_Number_Detected'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasADi -  WARNING(\"solver:nlp_grad_f failed: NaN detected for output grad_f_x, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_grad_f failed: NaN detected for output grad_f_x, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n"
     ]
    }
   ],
   "source": [
    "import aerosandbox as asb\n",
    "import aerosandbox.numpy as np\n",
    "\n",
    "opti = asb.Opti()\n",
    "\n",
    "x = opti.variable(init_guess=-1)\n",
    "\n",
    "opti.minimize(np.sqrt(x))\n",
    "\n",
    "try:\n",
    "    sol = opti.solve()\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected, this failed, reporting that \"Invalid number in NLP (NonLinear Program) function or derivative detected\".\n",
    "\n",
    "Okay, so what could we do better? Well, let's make two changes:\n",
    "\n",
    "1. Let's start from an initial guess of $x=1$, which will return a non-NaN value.\n",
    "2. Let's implement a constraint $x > 0$, which should keep the function $\\sqrt x$ from going into NaN territory.\n",
    "\n",
    "Now, this optimization problem should be well-posed, right?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.3, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        1\n",
      "Number of nonzeros in Lagrangian Hessian.............:        1\n",
      "\n",
      "Total number of variables............................:        1\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        1\n",
      "        inequality constraints with only lower bounds:        1\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 1.0000000e+000 0.00e+000 2.50e-001   0.0 0.00e+000    -  0.00e+000 0.00e+000   0\n",
      "   1 1.8447703e+000 0.00e+000 3.72e-001   0.4 2.40e+000    -  8.99e-001 1.00e+000f  1\n",
      "   2 1.8080897e+000 0.00e+000 1.34e-001  -1.6 1.34e-001   0.0 1.00e+000 1.00e+000f  1\n",
      "   3 1.6823475e+000 0.00e+000 1.48e-001  -2.3 4.39e-001  -0.5 1.00e+000 1.00e+000f  1\n",
      "   4 1.0476193e+000 0.00e+000 2.82e-001  -2.3 1.73e+000  -1.0 1.00e+000 1.00e+000f  1\n",
      "   5 1.0476188e-001 0.00e+000 4.42e+000  -2.3 1.25e+000  -0.5 1.00e+000 8.68e-001f  1\n",
      "   6 5.4016180e-002 0.00e+000 5.99e+000 -10.1 8.06e-003   2.6 1.00e+000 1.00e+000f  1\n",
      "   7 5.4007015e-003 0.00e+000 8.68e+001 -10.8 1.61e-002   3.0 1.00e+000 1.79e-001f  1\n",
      "   8 5.3082556e-004 0.00e+000 8.96e+002 -11.0 6.81e-005   6.2 1.00e+000 4.24e-001f  1\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "   9 3.7060324e-004 0.00e+000 1.03e+003 -11.0 4.01e-007   9.3 1.00e+000 3.60e-001f  2\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10 2.5379148e-004 0.00e+000 1.36e+003 -11.0 2.32e-007   9.7 1.00e+000 3.14e-001f  2\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "  11 1.6606357e-004 0.00e+000 2.03e+003 -11.0 1.48e-007  10.2 1.00e+000 2.49e-001f  2\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "  12 9.4744076e-005 0.00e+000 3.71e+003 -11.0 1.39e-007  10.6 1.00e+000 1.34e-001f  2\n",
      "  13 7.0837365e-005 0.00e+000 3.84e+003 -11.0 3.96e-009  11.9 1.00e+000 1.00e+000f  1\n",
      "  14 5.5465578e-005 0.00e+000 4.80e+003 -11.0 1.94e-009  12.3 1.00e+000 1.00e+000f  1\n",
      "  15 4.6737050e-005 0.00e+000 5.54e+003 -11.0 8.92e-010  12.8 1.00e+000 1.00e+000f  1\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "  16 1.6874305e-005 0.00e+000 2.21e+004 -10.5 7.60e-009  12.3 1.00e+000 2.50e-001f  3\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "  17 6.3111246e-006 0.00e+000 6.35e+004 -11.0 9.80e-010  13.6 1.00e+000 2.50e-001f  3\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "  18 3.7140253e-006 0.00e+000 1.00e+005 -11.0 1.04e-010  14.9 1.00e+000 2.50e-001f  3\n",
      "  19 3.1080572e-006 0.00e+000 8.35e+004 -11.0 4.13e-012  16.3 1.00e+000 1.00e+000f  1\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  20 2.1955435e-006 0.00e+000 1.30e+005 -11.0 3.87e-011  15.8 1.00e+000 1.25e-001f  4\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "  21 1.3691013e-006 0.00e+000 2.30e+005 -11.0 2.36e-011  16.2 1.00e+000 1.25e-001f  4\n",
      "  22 1.1306383e-006 0.00e+000 2.31e+005 -11.0 5.96e-013  17.6 1.00e+000 1.00e+000f  1\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "  23 6.4098033e-007 0.00e+000 4.92e+005 -11.0 6.94e-012  17.1 1.00e+000 1.25e-001f  4\n",
      "  24 4.6968502e-007 0.00e+000 5.84e+005 -11.0 1.90e-013  18.4 1.00e+000 1.00e+000f  1\n",
      "  25 3.5254175e-007 0.00e+000 7.70e+005 -11.0 9.63e-014  18.8 1.00e+000 1.00e+000f  1\n",
      "  26 2.7807395e-007 0.00e+000 9.55e+005 -11.0 4.70e-014  19.3 1.00e+000 1.00e+000f  1\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "Warning: Cutting back alpha due to evaluation error\n",
      "  27 1.9047087e-007 0.00e+000 1.54e+006 -11.0 5.25e-012  18.8 1.00e+000 7.81e-003f  8\n",
      "  28 1.1001631e-007 0.00e+000 3.46e+006 -11.0 2.42e-014  20.0 1.00e+000 1.00e+000f  1\n",
      "WARNING: Problem in step computation; switching to emergency mode.\n",
      "Restoration phase is called at point that is almost feasible,\n",
      "  with constraint violation 1.335396e-014. Abort.\n",
      "\n",
      "Number of Iterations....: 28\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  1.1001630983884095e-007   1.1001630983884095e-007\n",
      "Dual infeasibility......:  3.4626205448061009e+006   3.4626205448061009e+006\n",
      "Constraint violation....:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Complementarity.........:  1.0000000005629319e-011   1.0000000005629319e-011\n",
      "Overall NLP error.......:  6.3994605099958937e+002   3.4626205448061009e+006\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 55\n",
      "Number of objective gradient evaluations             = 29\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 55\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 29\n",
      "Number of Lagrangian Hessian evaluations             = 29\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.019\n",
      "Total CPU secs in NLP function evaluations           =      0.003\n",
      "\n",
      "EXIT: Restoration Failed!\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |   3.00ms ( 54.55us)   3.02ms ( 54.93us)        55\n",
      "       nlp_g  |        0 (       0)        0 (       0)        55\n",
      "  nlp_grad_f  |        0 (       0)        0 (       0)        30\n",
      "  nlp_hess_l  |        0 (       0)        0 (       0)        29\n",
      "   nlp_jac_g  |        0 (       0)        0 (       0)        30\n",
      "       total  |  28.00ms ( 28.00ms)  27.92ms ( 27.92ms)         1\n",
      "Error in Opti::solve [OptiNode] at .../casadi/core/optistack.cpp:159:\n",
      ".../casadi/core/optistack_internal.cpp:999: Assertion \"return_success(accept_limit)\" failed:\n",
      "Solver failed. You may use opti.debug.value to investigate the latest values of variables. return_status is 'Restoration_Failed'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_f failed: NaN detected for output f, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n"
     ]
    }
   ],
   "source": [
    "opti = asb.Opti()\n",
    "\n",
    "x = opti.variable(init_guess=1, lower_bound=0)\n",
    "\n",
    "opti.minimize(np.sqrt(x))\n",
    "\n",
    "try:\n",
    "    sol = opti.solve()\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nope! Technically this optimization problem is well-posed, but it is ill-posed for a gradient-based numerical solution, and therefore it fails to solve. Why?\n",
    "\n",
    "Because at $x=0$, the derivative of $\\sqrt(x)$ approaches infinity - this creates a NaN.\n",
    "\n",
    "So let's make another change. Instead of minimizing $\\sqrt x$, let's minimize $x ^ {1.5}$. This function has a derivative that approaches zero in the $x \\rightarrow 0$ limit. Let's see what happens:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.3, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        1\n",
      "Number of nonzeros in Lagrangian Hessian.............:        1\n",
      "\n",
      "Total number of variables............................:        1\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        1\n",
      "        inequality constraints with only lower bounds:        1\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 1.0000000e+000 0.00e+000 2.50e-001   0.0 0.00e+000    -  0.00e+000 0.00e+000   0\n",
      "   1 5.3995246e-002 0.00e+000 2.90e-001  -6.0 8.57e-001    -  1.00e+000 1.00e+000f  1\n",
      "   2 1.9259237e-002 0.00e+000 2.40e-002  -6.9 7.10e-002    -  1.00e+000 1.00e+000f  1\n",
      "   3 4.1395792e-003 0.00e+000 3.23e-002  -7.5 4.61e-002    -  1.00e+000 1.00e+000f  1\n",
      "   4 1.0007938e-003 0.00e+000 1.71e-002  -8.2 1.58e-002    -  1.00e+000 1.00e+000f  1\n",
      "   5 2.3485830e-004 0.00e+000 1.10e-002  -8.8 6.20e-003    -  1.00e+000 1.00e+000f  1\n",
      "   6 5.5524788e-005 0.00e+000 6.74e-003  -9.4 2.35e-003    -  1.00e+000 1.00e+000f  1\n",
      "   7 1.3102653e-005 0.00e+000 4.18e-003 -10.0 9.00e-004    -  1.00e+000 1.00e+000f  1\n",
      "   8 3.0933251e-006 0.00e+000 2.58e-003 -10.7 3.43e-004    -  1.00e+000 1.00e+000f  1\n",
      "   9 7.3016884e-007 0.00e+000 1.59e-003 -11.0 1.31e-004    -  1.00e+000 1.00e+000f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10 1.7234156e-007 0.00e+000 9.86e-004 -11.0 5.01e-005    -  1.00e+000 1.00e+000f  1\n",
      "  11 4.0667762e-008 0.00e+000 6.09e-004 -11.0 1.91e-005    -  1.00e+000 1.00e+000f  1\n",
      "  12 9.5915429e-009 0.00e+000 3.77e-004 -11.0 7.31e-006    -  1.00e+000 1.00e+000f  1\n",
      "  13 2.2601887e-009 0.00e+000 2.33e-004 -11.0 2.79e-006    -  1.00e+000 1.00e+000f  1\n",
      "  14 5.3242492e-010 0.00e+000 1.44e-004 -11.0 1.07e-006    -  1.00e+000 1.00e+000f  1\n",
      "  15 1.2636353e-010 0.00e+000 8.82e-005 -11.0 4.05e-007    -  1.00e+000 1.00e+000f  1\n",
      "  16 1.1378662e-010 0.00e+000 4.44e-007  -9.8 1.70e-008    -  1.00e+000 1.00e+000f  1\n",
      "  17 2.3909507e-011 0.00e+000 5.98e-005 -11.0 1.52e-007    -  1.00e+000 1.00e+000f  1\n",
      "  18 2.1826491e-011 0.00e+000 1.94e-007 -10.4 4.89e-009    -  1.00e+000 1.00e+000f  1\n",
      "  19 7.1273778e-012 0.00e+000 2.03e-005 -11.0 4.11e-008    -  1.00e+000 1.00e+000f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  20 6.0146079e-012 0.00e+000 4.37e-007 -10.9 3.96e-009    -  1.00e+000 1.00e+000f  1\n",
      "  21 4.9876017e-012 0.00e+000 4.99e-007 -11.0 3.88e-009    -  1.00e+000 1.00e+000f  1\n",
      "  22 4.9611824e-012 0.00e+000 4.01e-010 -11.0 1.03e-010    -  1.00e+000 1.00e+000f  1\n",
      "\n",
      "Number of Iterations....: 22\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  4.9611824145824379e-012   4.9611824145824379e-012\n",
      "Dual infeasibility......:  4.0090739251595273e-010   4.0090739251595273e-010\n",
      "Constraint violation....:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Complementarity.........:  1.0000098247274144e-011   1.0000098247274144e-011\n",
      "Overall NLP error.......:  4.0090739251595273e-010   4.0090739251595273e-010\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 23\n",
      "Number of objective gradient evaluations             = 23\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 23\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 23\n",
      "Number of Lagrangian Hessian evaluations             = 22\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.009\n",
      "Total CPU secs in NLP function evaluations           =      0.000\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |        0 (       0)        0 (       0)        23\n",
      "       nlp_g  |        0 (       0)        0 (       0)        23\n",
      "  nlp_grad_f  |        0 (       0)        0 (       0)        24\n",
      "  nlp_hess_l  |        0 (       0)        0 (       0)        22\n",
      "   nlp_jac_g  |        0 (       0)        0 (       0)        24\n",
      "       total  |  11.00ms ( 11.00ms)  11.00ms ( 11.00ms)         1\n"
     ]
    }
   ],
   "source": [
    "opti = asb.Opti()\n",
    "\n",
    "x = opti.variable(init_guess=1, lower_bound=0)\n",
    "\n",
    "opti.minimize(x ** 1.5)\n",
    "\n",
    "sol = opti.solve()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This solves - nice!\n",
    "\n",
    "One thing to know on this note: IPOPT does something it calls \"bounds pushing\" - this is detailed in the excellent original IPOPT paper by Andreas Waechter, but the basic idea is that IPOPT solver performance seems to improve if the feasible space is extended by a small amount ($\\epsilon \\approx 10^{-8}$). In cases like this, that has the potential to allow a function like $x^{1.5}$ bounded by $x>0$ to go very slightly negative and NaN. IPOPT has lots of tools to help get the iterate back into the well-posed design space, but just be aware of this possibility.\n",
    "\n",
    "Let's talk about one last possibility, and an issue that can come up with conditionals.\n",
    "\n",
    "Imagine we have the problem:\n",
    "\n",
    "* Minimize $f(x)$, where\n",
    "* $f(x) = \\begin{cases}\n",
    "x^{1.5} & \\text{for } x\\geq 0\\\\\n",
    "(-x)^{1.5} & \\text{for } x < 0 \\\\\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "Note that $f(x)$ is a $C_1$-continuous function - both its value and derivative are continuous everywhere. Also, note that $f(x)$ should never return NaN for any input value $x$.\n",
    "\n",
    "Let's see what happens when we try to solve this:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.3, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        1\n",
      "\n",
      "Error evaluating objective gradient at user provided starting point.\n",
      "  No scaling factor for objective function computed!\n",
      "Total number of variables............................:        1\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "\n",
      "Number of Iterations....: 0\n",
      "\n",
      "Number of objective function evaluations             = 0\n",
      "Number of objective gradient evaluations             = 1\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 0\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.000\n",
      "Total CPU secs in NLP function evaluations           =      0.000\n",
      "\n",
      "EXIT: Invalid number in NLP function or derivative detected.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "  nlp_grad_f  |        0 (       0)        0 (       0)         2\n",
      "       total  |        0 (       0)        0 (       0)         1\n",
      "Error in Opti::solve [OptiNode] at .../casadi/core/optistack.cpp:159:\n",
      ".../casadi/core/optistack_internal.cpp:999: Assertion \"return_success(accept_limit)\" failed:\n",
      "Solver failed. You may use opti.debug.value to investigate the latest values of variables. return_status is 'Invalid_Number_Detected'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasADi -  WARNING(\"solver:nlp_grad_f failed: NaN detected for output grad_f_x, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi -  WARNING(\"solver:nlp_grad_f failed: NaN detected for output grad_f_x, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n"
     ]
    }
   ],
   "source": [
    "opti = asb.Opti()\n",
    "\n",
    "x = opti.variable(init_guess=1)\n",
    "\n",
    "f = np.where(\n",
    "    x >= 0,\n",
    "    x ** 1.5,\n",
    "    (-x) ** 1.5\n",
    ")\n",
    "\n",
    "opti.minimize(f)\n",
    "\n",
    "try:\n",
    "    sol = opti.solve()\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This errored too! Why?\n",
    "\n",
    "Because the *intermediate values* of $x^{1.5}$ in `np.where()` are NaN. In the current functionality of `np.where()`, if either value is NaN, the result is NaN (regardless of the value of `condition`) - this will hopefully be fixed in the future.\n",
    "\n",
    "For now, you can bypass this problem by using `np.fabs(x)` or `np.fmax(x, 0)` to ensure that each piece of the conditional is non-NaN (even for values that will never be used):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.3, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        1\n",
      "\n",
      "Total number of variables............................:        1\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 1.0000000e+000 0.00e+000 1.50e+000   0.0 0.00e+000    -  0.00e+000 0.00e+000   0\n",
      "   1 0.0000000e+000 0.00e+000 0.00e+000 -11.0 2.00e+000    -  1.00e+000 5.00e-001f  2\n",
      "\n",
      "Number of Iterations....: 1\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Dual infeasibility......:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Constraint violation....:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Complementarity.........:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "Overall NLP error.......:  0.0000000000000000e+000   0.0000000000000000e+000\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 7\n",
      "Number of objective gradient evaluations             = 2\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 1\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.001\n",
      "Total CPU secs in NLP function evaluations           =      0.000\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |        0 (       0)        0 (       0)         7\n",
      "  nlp_grad_f  |        0 (       0)        0 (       0)         3\n",
      "  nlp_hess_l  |        0 (       0)        0 (       0)         1\n",
      "       total  |   2.00ms (  2.00ms)   1.98ms (  1.98ms)         1\n",
      "x = 0.0\n"
     ]
    }
   ],
   "source": [
    "opti = asb.Opti()\n",
    "\n",
    "x = opti.variable(init_guess=1)\n",
    "\n",
    "f = np.where(\n",
    "    x > 0,\n",
    "    np.fmax(x, 0) ** 1.5,\n",
    "    np.fabs(x) ** 1.5\n",
    ")\n",
    "\n",
    "opti.minimize(f)\n",
    "\n",
    "\n",
    "sol = opti.solve()\n",
    "\n",
    "print(f\"x = {sol.value(x)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This works, and it indicates that the optimum is `x = 0` as expected."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}